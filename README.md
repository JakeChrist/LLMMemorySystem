# LLMemory System

LLMemory is a small demonstration of a local-first memory architecture for language model agents.  
It supports episodic, semantic and procedural memories, retrieval based on embeddings and tags, mood analysis and optional background "dreaming" summaries.  An LLM backend can be swapped out using a pluggable interface.

## Usage

`main.py` is the entry point and exposes three modes:

```
python main.py MODE [--llm NAME] [--db PATH]
```

- **MODE** – `cli`, `gui` or `repl`
- **--llm** – which backend to use (`local`, `openai`, `claude`, `gemini`, `lmstudio`)
- **--db** – path to the SQLite database used for persistence

### Command line interface

Running `python main.py cli` invokes `cli.memory_cli` which provides a set of subcommands:

```
list                  # list stored memories
add TEXT [--model MODEL]
query TEXT [--top-k N] [--model MODEL]
reset
edit TIMESTAMP TEXT
delete TIMESTAMP
list-sem | add-sem TEXT | edit-sem TIMESTAMP TEXT | delete-sem TIMESTAMP
list-proc | add-proc TEXT | edit-proc TIMESTAMP TEXT | delete-proc TIMESTAMP
start-dream [--interval SECS] [--llm NAME]
stop-dream
```

`start-dream` runs continuously until interrupted with `Ctrl+C`. The
`stop-dream` command only works when the dreaming scheduler is started
programmatically in the same process.

To ingest archived conversations or biographies into an agent database use the
import helpers:

```bash
python main.py cli add-conversation transcript.txt --agent Thorne
python main.py cli add-biography bio.txt --agent Thorne
```

See [docs/memory_constructor.md](docs/memory_constructor.md) for a detailed
description of the ingestion process and GUI options.

### REPL and GUI

```
python main.py repl --llm openai
python main.py gui  --llm local
```

The REPL mode starts a simple console conversation loop.  The GUI mode launches
the PyQt5 interface defined in `gui/qt_interface.py`. When the GUI starts a
`CognitiveScheduler` automatically begins monitoring idle time and triggers the
thinking and dreaming engines.  The scheduler uses the same `--llm` backend so
background thoughts are generated by the selected model.
For details on automated reasoning and planning see
[docs/reasoning_engine.md](docs/reasoning_engine.md).

## Requirements

The project only relies on the Python standard library for basic operation.  The packages below enable optional features:

- `sentence-transformers` – real text embeddings
- `transformers` – sentiment analysis for emotions
- `openai`, `anthropic`, `google-generativeai`, `requests` – alternative or helper LLM backends (OpenAI, Claude, Gemini, LMStudio)
- `PyQt5` – graphical interface
- `numpy`, `faiss` – vector index acceleration
- `pyyaml` – reading YAML config files
- `pytest` – running the unit tests

Install everything using:

```
pip install -r requirements.txt
```

## Running the tests

Unit tests are located in the `tests/` directory and can be executed with:

```
pytest
```

## Emotions & Mood

Memories record the emotion labels detected in the text along with an intensity score for each label. These labels are normalised to one of the following categories:

- angry
- disgust
- embarrassed
- fear
- happy
- love
- neutral
- pleasure
- sad
- surprise

The intensity scores are stored in `MemoryEntry.emotion_scores` and used by the `Retriever`. When the agent's current `mood` matches a stored emotion, that memory receives a boost in ranking.

Example:
```python
from core.memory_entry import MemoryEntry
from retrieval.retriever import Retriever

m1 = MemoryEntry(content="lost my toy", embedding=["a"], emotions=["sad"], emotion_scores={"sad": 0.9})
m2 = MemoryEntry(content="found a toy", embedding=["a"], emotions=["happy"], emotion_scores={"happy": 0.8})
retriever = Retriever([m1, m2])
top = retriever.query("toy", mood="sad")[0]
print(top.content)  # -> "lost my toy"
```

All user messages, assistant replies, introspective thoughts and dream
summaries are analyzed for emotional tone.  The detected labels and
scores are stored with each memory entry.

## License

This project is licensed under the [MIT License](LICENSE). Copyright (c) 2024 Jacob Christ.
